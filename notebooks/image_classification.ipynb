{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72ad016-53b9-45c0-8460-1bbcb1dda322",
   "metadata": {},
   "source": [
    "# Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc3c34-45cc-45df-8a24-2a132d3a1749",
   "metadata": {},
   "source": [
    "Nesse notebook, irei construir um modelo de classificação de imagens, o modelo será treinado com imagens de gatos e cachorros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a213c46-a0cd-46ad-8af2-5c14cbe8557a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f2d40-3a40-433a-96e7-4cec442d0fac",
   "metadata": {},
   "source": [
    "## Loading and processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759b6da-ea6c-465c-9a34-ce12f4eed05a",
   "metadata": {},
   "source": [
    "As imagens estão no meu diretório home, em uma pasta chamada cats_and_dogs, e dentro dessa pasta há duas pastas, uma de cats e uma de dogs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f7208-125a-4619-ba7f-7baf7a47a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_file_paths(directory):\n",
    "    \"\"\"        \n",
    "    Create a list with the absolute path of files inside directory\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    filepaths = []\n",
    "    \n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for file in filenames:\n",
    "            filepaths.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "    \n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc7125e-36bf-45bd-848f-ce4a5e074e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "home_directory = os.path.expanduser(\"~\")\n",
    "images_folder = \"cats_and_dogs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c8d87-2696-4840-9402-179da602ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = absolute_file_paths(os.path.join(home_directory, images_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80f3df-b66a-4ff1-85c6-ae539248e70b",
   "metadata": {},
   "source": [
    "O próximo passo é gerar a lista de rótulos a partir do caminho de cada imagem, cada caminho terá o nome da classe, irei retornar 0 para gato e 1 para cachorro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef31d1-b987-41b5-ba28-9f2e90edfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {\n",
    "    \"cat\": 0,\n",
    "    \"dog\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025961b6-ca88-46dd-8d89-a486e5f36570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(filepath, category_dict):\n",
    "    category = filepath.split(\"/\")[-2]\n",
    "    return category_dict[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6301b-7803-40fb-901f-948c48fb4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [generate_label(path, category_dict) for path in filepaths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34463f-cce7-45f4-b711-5dd1a70b66d0",
   "metadata": {},
   "source": [
    "Nessa próxima etapa, vou dividir os dados em dados de treino e dados de teste usando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc4f17-8415-4105-8993-20a22c40949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    filepaths, labels, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b000dde-3a42-458f-87d3-38b7250a9f33",
   "metadata": {},
   "source": [
    "Agora vou criar o datagenerator, que vai alimentar o modelos durante o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0491e2-c502-43e6-bb7b-272eefec5d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor():\n",
    "    return None\n",
    "\n",
    "def create_generator(x, y):\n",
    "    return None\n",
    "\n",
    "def chunk(array, batch_size=32):\n",
    "    \"\"\"Transform an array into batches\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array : list\n",
    "        List of items\n",
    "    \n",
    "    batch_size: int, optional\n",
    "        Size of batch (default is 32)\n",
    "\n",
    "    Returns\n",
    "    __________\n",
    "    data_generator: data_generator\n",
    "        List, each item of list, is an line of .csv file\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(0, len(array), batch_size):\n",
    "        yield array[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04136a-7933-4907-b2c2-94d8181a82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_generator(x_train, y_train)\n",
    "test_data = create_generator(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6666f94-63ee-4879-9260-d2d6a33dfbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_batch_v2(file_list, batch_size=32, flat_image=False, color_mode=\"rgb\", \n",
    "              shape=None, rescaling=True, dataset_path=''):\n",
    "    \"\"\"\n",
    "    Fit list of files to an array in batches.\n",
    "        Args:\n",
    "            file_list (list): list of files with full path\n",
    "            batch_size (int, optional): Batch size. Defaults to 32.\n",
    "            flat_image (bool, optional): Whether to convert the image into a\n",
    "                vector. Defaults to True.\n",
    "            color_mode (str, optional): color mode. Defaults to bgr\n",
    "            shape (tuple, optional): shape of the images if resizing is necessary.\n",
    "                    Defaults to None\n",
    "\n",
    "        Yields:\n",
    "            tuple: dataset as a numpy array (m_samples, n_pixels)\n",
    "        \"\"\"\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        \n",
    "        data = []\n",
    "        files_list = []\n",
    "        \n",
    "        for file in file_list[i:i + batch_size]:\n",
    "            if dataset_path != '':\n",
    "                file = os.path.join(dataset_path, file)\n",
    "            image = cv2.imread(file)\n",
    "            if shape:\n",
    "                image_resized = cv2.resize(image, shape)\n",
    "                image = image_resized\n",
    "            if color_mode == \"rgb\":\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            if flat_image:\n",
    "                image = image.ravel()\n",
    "            if rescaling:\n",
    "                image = image / 255.\n",
    "            data.append(image)\n",
    "            \n",
    "            files_list.append(file)\n",
    "            \n",
    "        yield [np.array(data, dtype=np.float32), files_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed2ca2-fa87-45dc-9a44-e112ef88e64b",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760287c-cadf-4ab4-92d6-df305218bd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01d23201-f231-47e3-8d5b-b92178d46d30",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e986232-da32-4aa3-8186-9256f34bcd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "985df57a-61b2-4460-81b3-3f416daf0b1b",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f67779-6a74-44af-ab95-281bdcd79cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd1548-0782-44fe-b74c-73e1321405d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a7475-0123-4309-82fd-128f09a91a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0948ea-78e3-4f32-b600-620fccdde641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b435f-0ff1-4e49-a630-09a63499bc92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
